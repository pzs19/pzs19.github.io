---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Zhuoshi Pan (ÁõòÂçìÂÆû in Chinese) is currently a graduate student at [School of Information Science and Technology (SIST)](https://www.sist.tsinghua.edu.cn/) in [Tsinghua University (THU)](https://www.tsinghua.edu.cn/), supervised by [Prof. H. Vicky Zhao](https://ieeexplore.ieee.org/author/37294624300). He got the B.E. degree from [School of Information Science and Technology (SIST)](https://www.sist.tsinghua.edu.cn/), [Tsinghua University (THU)](https://www.tsinghua.edu.cn/) in 2023. 

He currently is an intern of [Microsoft DKI Group](https://www.microsoft.com/en-us/research/group/data-knowledge-intelligence/). He is very fortunate to be mentored by [Dr. Qianhui Wu](https://www.microsoft.com/en-us/research/people/qianhuiwu/). He also works closely with [Huiqiang Jiang](https://www.microsoft.com/en-us/research/people/hjiang/).

His researches focus on natural language processing and efficient LLM. 

<!-- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. Suspendisse condimentum, libero vel tempus mattis, risus risus vulputate libero, elementum fermentum mi neque vel nisl. Maecenas facilisis maximus dignissim. Curabitur mattis vulputate dui, tincidunt varius libero luctus eu. Mauris mauris nulla, scelerisque eget massa id, tincidunt congue felis. Sed convallis tempor ipsum rhoncus viverra. Pellentesque nulla orci, accumsan volutpat fringilla vitae, maximus sit amet tortor. Aliquam ultricies odio ut volutpat scelerisque. Donec nisl nisl, porttitor vitae pharetra quis, fringilla sed mi. Fusce pretium dolor ut aliquam consequat. Cras volutpat, tellus accumsan mattis molestie, nisl lacus tempus massa, nec malesuada tortor leo vel quam. Aliquam vel ex consectetur, vehicula leo nec, efficitur eros. Donec convallis non urna quis feugiat. -->

<!-- My research interest includes neural machine translation and computer vision. I have published more than 100 papers at the top international AI conferences with total <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'>google scholar citations <strong><span id='total_cit'>260000+</span></strong></a> (You can also use google scholar badge <a href='https://scholar.google.com/citations?user=DhtAFkwAAAAJ'><img src="https://img.shields.io/endpoint?url={{ url | url_encode }}&logo=Google%20Scholar&labelColor=f6f6f6&color=9cf&style=flat&label=citations"></a>). -->


# üî• News
- *2024.03*: &nbsp; One paper about efficient LLM was submitted to [Arxiv](https://arxiv.org/abs/2403.12968).
- *2023.11*: &nbsp; One paper about data poisoning on Diffusion Models was submitted to [Arxiv](https://arxiv.org/abs/2311.02373).
- *2023.10*: &nbsp;üéâüéâ One paper accepted by [NeurIPS 2023 Workshop on BUGS](https://nips.cc/virtual/2023/77108). Thanks for all collaborators!

# üìù Publications
<div class='paper-box'><div class='paper-box-image'><div><div class="badge">  </div><img src='images/LLMLingua-2.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[LLMLingua-2: Data Distillation for Efficient and Faithful Task-Agnostic Prompt Compression](https://arxiv.org/abs/2403.12968) \\
**Zhuoshi Pan**, Qianhui Wu, Huiqiang Jiang, Menglin Xia, Xufang Luo, Jue Zhang, Qingwei Lin, Victor R√ºhle, Yuqing Yang, Chin-Yew Lin, H. Vicky Zhao, Lili Qiu, Dongmei Zhang

<!-- [**Project**](https://llmlingua.com/llmlingua2.html) \| [![](https://img.shields.io/github/stars/QizhiPei/FABind?style=social&label=Code)](https://github.com/microsoft/LLMLingua/) \| [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-blue?label=Model)](https://huggingface.co/spaces/microsoft/llmlingua-2) -->

[**Project**](https://llmlingua.com/llmlingua2.html) \| [![](https://img.shields.io/github/stars/QizhiPei/FABind?style=social&label=Code+Stars)](https://github.com/microsoft/LLMLingua/) \| [![Hugging Face](https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-blue?label=Model)](https://huggingface.co/spaces/microsoft/llmlingua-2)

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge"> </div><img src='images/BiBadDiff.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[From Trojan Horses to Castle Walls: Unveiling Bilateral Backdoor Effects in Diffusion Models](https://arxiv.org/abs/2311.02373) \\
**Zhuoshi Pan**(co-first author), Yuguang Yao, Gaowen Liu, Bingquan Shen, H. Vicky Zhao, Ramana Rao Kompella, Sijia Liu

[**Project**](https://github.com/OPTML-Group/BiBadDiff) \| [![](https://img.shields.io/github/stars/QizhiPei/BioT5?style=social&label=Code+Stars)](https://github.com/OPTML-Group/BiBadDiff) 
</div>
</div>

# üéñ Honors and Awards
- *2020~2022*, Academic Excellence Scholarship, THU.
- *2019*, Freshman Scholarship, THU. 

# üìñ Educations
- *2023.09 - Now*, graduate student in the School of Information Science and Technology (SIST), Tsinghua University (THU).
- *2019.09 - 2023.06*, undergraduate student in the School of Information Science and Technology (SIST), Tsinghua University (THU).

<!-- # üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/) -->

# üíª Internships
- *2023.12 - Now*, [Microsoft DKI Group](https://www.microsoft.com/en-us/research/group/data-knowledge-intelligence/), Beijing, China.
- *2022.06 - 2022.10*, [XiaoIce Company](https://xiaoice.com/), Beijing, China.